#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import torch
import time
import platform
from datetime import datetime


def check_basic_info():
    """æ£€æŸ¥åŸºç¡€ä¿¡æ¯"""
    print("ğŸ”§ === åŸºç¡€ç¯å¢ƒæ£€æŸ¥ ===")
    print(f"Pythonç‰ˆæœ¬: {platform.python_version()}")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")


def check_gpu():
    """æ£€æŸ¥GPU"""
    print("\nğŸš€ === GPUæ£€æŸ¥ ===")

    if torch.cuda.is_available():
        print("âœ… CUDA å¯ç”¨!")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")

        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            props = torch.cuda.get_device_properties(i)
            print(f"  æ˜¾å­˜: {props.total_memory / 1024 ** 3:.1f} GB")

            # æ¸…ç†æ˜¾å­˜å¹¶æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
            torch.cuda.empty_cache()
            allocated = torch.cuda.memory_allocated(i) / 1024 ** 3
            print(f"  å½“å‰ä½¿ç”¨: {allocated:.2f} GB")

        return True
    else:
        print("âŒ CUDA ä¸å¯ç”¨")
        print("ğŸ’¡ å°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
        return False


def check_memory():
    """æ£€æŸ¥å†…å­˜ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    print("\nğŸ’¾ === å†…å­˜æ£€æŸ¥ ===")

    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"æ€»å†…å­˜: {memory.total / 1024 ** 3:.1f} GB")
        print(f"å¯ç”¨å†…å­˜: {memory.available / 1024 ** 3:.1f} GB")
        print(f"ä½¿ç”¨ç‡: {memory.percent:.1f}%")

        if memory.available / 1024 ** 3 < 4:
            print("âš ï¸  å¯ç”¨å†…å­˜è¾ƒå°‘ï¼Œå»ºè®®å…³é—­å…¶ä»–ç¨‹åº")
        else:
            print("âœ… å†…å­˜å……è¶³")

    except ImportError:
        print("âš ï¸  psutilæœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥å†…å­˜")
    except Exception as e:
        print(f"âš ï¸  å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")


def test_model_basic():
    """åŸºç¡€æ¨¡å‹æµ‹è¯•"""
    print("\nğŸ§ª === æ¨¡å‹æµ‹è¯• ===")

    try:
        from solution import OriginalSVDNet

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")

        # åˆ›å»ºæ¨¡å‹
        model = OriginalSVDNet(dim=64, rank=32).to(device)
        total_params = sum(p.numel() for p in model.parameters())
        print(f"æ¨¡å‹å‚æ•°: {total_params:,}")

        # æµ‹è¯•æ¨ç†
        dummy_input = torch.randn(64, 64, 2, device=device)

        # é¢„çƒ­
        for _ in range(3):
            with torch.no_grad():
                _ = model(dummy_input)

        # è®¡æ—¶
        if device.type == 'cuda':
            torch.cuda.synchronize()

        start_time = time.time()
        num_runs = 10

        for _ in range(num_runs):
            with torch.no_grad():
                U, S, V = model(dummy_input)

        if device.type == 'cuda':
            torch.cuda.synchronize()

        end_time = time.time()
        avg_time = (end_time - start_time) / num_runs

        print(f"âœ… æ¨ç†æµ‹è¯•æˆåŠŸ")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time * 1000:.2f} ms")
        print(f"è¾“å‡ºå½¢çŠ¶: U{list(U.shape)}, S{list(S.shape)}, V{list(V.shape)}")

        # æ˜¾å­˜ä½¿ç”¨ï¼ˆå¦‚æœæ˜¯GPUï¼‰
        if device.type == 'cuda':
            memory_used = torch.cuda.max_memory_allocated(device) / 1024 ** 2
            print(f"å³°å€¼æ˜¾å­˜: {memory_used:.1f} MB")

        return True

    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥solution.py - è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨")
        return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def estimate_training():
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    print("\nâ±ï¸  === è®­ç»ƒæ—¶é—´ä¼°ç®— ===")

    has_gpu = torch.cuda.is_available()

    if has_gpu:
        gpu_name = torch.cuda.get_device_name(0)
        print(f"GPU: {gpu_name}")

        # ç®€å•ä¼°ç®—
        if any(x in gpu_name.upper() for x in ['RTX 40', 'RTX 30', 'V100', 'A100']):
            estimated_hours = 1.5
            print("ğŸš€ é«˜æ€§èƒ½GPU - é¢„è®¡è®­ç»ƒæ—¶é—´: 1-2å°æ—¶")
        elif any(x in gpu_name.upper() for x in ['RTX 20', 'GTX 16', 'GTX 10']):
            estimated_hours = 3
            print("âš¡ ä¸­ç­‰æ€§èƒ½GPU - é¢„è®¡è®­ç»ƒæ—¶é—´: 2-4å°æ—¶")
        else:
            estimated_hours = 6
            print("ğŸŒ å…¥é—¨çº§GPU - é¢„è®¡è®­ç»ƒæ—¶é—´: 4-8å°æ—¶")
    else:
        print("ğŸŒ CPUè®­ç»ƒ - é¢„è®¡è®­ç»ƒæ—¶é—´: 8-24å°æ—¶")
        print("ğŸ’¡ å¼ºçƒˆå»ºè®®ä½¿ç”¨GPUä»¥è·å¾—æ›´å¿«é€Ÿåº¦")


def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    print("\nğŸ“‚ === æ•°æ®æ–‡ä»¶æ£€æŸ¥ ===")

    import os

    required_files = [
        "DebugData/Round0CfgData1.txt",
        "CompetitionData1/Round1CfgData1.txt",
        "CompetitionData1/Round1TrainData1.npy",
        "CompetitionData1/Round1TrainLabel1.npy"
    ]

    missing_files = []
    existing_files = []

    for file_path in required_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / 1024 / 1024
            print(f"âœ… {file_path} ({size_mb:.1f} MB)")
            existing_files.append(file_path)
        else:
            print(f"âŒ {file_path}")
            missing_files.append(file_path)

    if missing_files:
        print(f"\nâš ï¸  ç¼ºå°‘ {len(missing_files)} ä¸ªæ–‡ä»¶")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨æ­£ç¡®ä½ç½®")
    else:
        print(f"\nâœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶éƒ½å­˜åœ¨!")

    return len(missing_files) == 0


def main():
    """ä¸»æ£€æµ‹æµç¨‹"""
    print("ğŸ” === ç®€åŒ–ç³»ç»Ÿæ£€æµ‹ ===")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 40)

    success_count = 0
    total_checks = 5

    try:
        # åŸºç¡€æ£€æŸ¥
        check_basic_info()
        success_count += 1

        # GPUæ£€æŸ¥
        if check_gpu():
            success_count += 1

        # å†…å­˜æ£€æŸ¥
        check_memory()
        success_count += 1

        # æ¨¡å‹æµ‹è¯•
        if test_model_basic():
            success_count += 1

        # æ•°æ®æ–‡ä»¶æ£€æŸ¥
        if check_data_files():
            success_count += 1

        # è®­ç»ƒä¼°ç®—
        estimate_training()

        print("\n" + "=" * 40)
        print(f"æ£€æµ‹å®Œæˆ: {success_count}/{total_checks} é¡¹é€šè¿‡")

        if success_count >= 4:
            print("ğŸ‰ ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ!")
            print("ğŸ’¡ è¿è¡Œ: python simple_train.py")
        elif success_count >= 2:
            print("âš ï¸  ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œä½†å¯èƒ½æœ‰æ€§èƒ½é—®é¢˜")
            print("ğŸ’¡ å¯ä»¥å°è¯•è¿è¡Œè®­ç»ƒï¼Œä½†å»ºè®®è§£å†³é—®é¢˜")
        else:
            print("âŒ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œå»ºè®®å…ˆè§£å†³å†è®­ç»ƒ")

    except Exception as e:
        print(f"\nâŒ æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥Pythonç¯å¢ƒ")


if __name__ == "__main__":
    main()